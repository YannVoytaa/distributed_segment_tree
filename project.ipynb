{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "0ERthLLNYvVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d407e32-c505-4872-b7be-ff0e145e0c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in ./.local/lib/python3.9/site-packages (3.3.2)\r\n",
            "Requirement already satisfied: py4j==0.10.9.5 in ./.local/lib/python3.9/site-packages (from pyspark) (0.10.9.5)\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUw3-6oKg32w",
        "outputId": "3572fe92-9460-49b9-8244-64a6513931bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\r\n",
            "   creating: 2dims/\r\n",
            "  inflating: 2dims/part-00000        \r\n",
            " extracting: 2dims/_SUCCESS          \r\n",
            " extracting: 2dims/.part-00000.crc   \r\n",
            " extracting: 2dims/._SUCCESS.crc     \r\n",
            "  inflating: 2dims/part-00001        \r\n",
            " extracting: 2dims/.part-00001.crc   \r\n",
            "   creating: 3dims/\r\n",
            "  inflating: 3dims/part-00000        \r\n",
            " extracting: 3dims/_SUCCESS          \r\n",
            " extracting: 3dims/.part-00000.crc   \r\n",
            " extracting: 3dims/._SUCCESS.crc     \r\n",
            "  inflating: 3dims/part-00001        \r\n",
            " extracting: 3dims/.part-00001.crc   \r\n",
            "   creating: example_test/\r\n",
            "  inflating: example_test/part-00000  \r\n",
            " extracting: example_test/_SUCCESS   \r\n",
            " extracting: example_test/.part-00000.crc  \r\n",
            " extracting: example_test/._SUCCESS.crc  \r\n",
            "  inflating: example_test/part-00001  \r\n",
            " extracting: example_test/.part-00001.crc  \r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = False"
      ],
      "metadata": {
        "id": "qGxhxIJm3mh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdqZ380vXyQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd35dbf1-a872-45c7-8061-00af01db9ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/05/29 12:12:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "if test:\n",
        "  spark = SparkSession.builder \\\n",
        "                      .master(\"local[*]\") \\\n",
        "                      .config(\"spark.executor.memory\", \"4g\") \\\n",
        "                      .config(\"spark.driver.memory\", \"1g\") \\\n",
        "                      .appName(\"mlibs\") \\\n",
        "                      .getOrCreate()\n",
        "else:\n",
        "  spark = SparkSession.builder \\\n",
        "                    .master(\"spark://master:7077\") \\\n",
        "                    .config(\"spark.executor.memory\", \"1g\") \\\n",
        "                    .config(\"spark.driver.memory\", \"3g\") \\\n",
        "                    .appName(\"mlibs\") \\\n",
        "                    .getOrCreate()\n",
        "sc = spark.sparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MACHINES_NUMBER = 3"
      ],
      "metadata": {
        "id": "H-sPHY3iT5ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -rm -r -f /input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCaOTYewrtUd",
        "outputId": "3d60b504-7c19-4c4a-d1fe-ba869f044061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-29 12:12:13,280 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Deleted /input.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwAq_saIsVRH",
        "outputId": "17543130-66c2-423a-b52e-a28cbd5b273b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2dims\t 3dims\t'=0.0.7'   balladyna.txt   data.zip   example_test\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -put example_test /input.txt\n",
        "!hdfs dfs -ls /\n",
        "\n",
        "t = sc.textFile('hdfs://master:9000/input.txt')\n",
        "t.take(20)"
      ],
      "metadata": {
        "id": "Lw-vSoj_J9w-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766775d1-04a9-4783-d2a5-76dfd7bd8794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-29 12:12:18,425 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "2023-05-29 12:12:22,018 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Found 3 items\n",
            "-rw-r--r--   3 jw429685 supergroup     199726 2023-03-27 13:39 /balladyna.txt\n",
            "drwxr-xr-x   - jw429685 supergroup          0 2023-05-29 12:12 /input.txt\n",
            "drwxr-xr-x   - jw429685 supergroup          0 2023-03-27 13:36 /test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(1, 5, False)',\n",
              " '(3, 8, True)',\n",
              " '(4, 2, False)',\n",
              " '(5, 9, True)',\n",
              " '(6, 7, False)',\n",
              " '(7, 3, True)',\n",
              " '(8, 1, False)',\n",
              " '(9, 4, True)']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "df = t.map(lambda v: ast.literal_eval(v))\n",
        "df.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lPg8tCXhoXc",
        "outputId": "2ac25a61-7233-4d58-bcda-23a0a2687888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 5, False),\n",
              " (3, 8, True),\n",
              " (4, 2, False),\n",
              " (5, 9, True),\n",
              " (6, 7, False),\n",
              " (7, 3, True),\n",
              " (8, 1, False),\n",
              " (9, 4, True)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "G-4vRlf1fmfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test generator\n",
        "if test:\n",
        "  N = 1_000_000\n",
        "  VAL_RANGE_MULTIPLIER = 10_000\n",
        "  DIMS = 2\n",
        "  x_ys = random.sample(range(N * VAL_RANGE_MULTIPLIER), DIMS * N)\n",
        "  data = [(*[x_ys[DIMS * i + mod]  for mod in range(DIMS)], random.choice([True, False])) for i in range(N)]\n",
        "  #data = [(x_ys[2 * i], x_ys[2 * i + 1], random.choice([True, False])) for i in range(N)]\n",
        "  #data = [(1,5, False), (3,8, True), (4,2, False), (5,9,True), (6,7, False), (7,3, True), (8,1, False), (9,4, True)]\n",
        "  df = sc.parallelize(data)\n",
        "  #df.saveAsTextFile(\"example_test\")\n",
        "  #data_frame = df.toDF()\n",
        "  #data_frame.write.mode(\"overwrite\").parquet('df_example')\n",
        "  #input = spark.read.parquet('df_example')\n",
        "  #input.rdd.collect()"
      ],
      "metadata": {
        "id": "d4lIyz-dp5H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bisect\n",
        "t = MACHINES_NUMBER\n",
        "\n",
        "def terasort(input, key_fn=lambda x: x, include_ranking=False):\n",
        "  n = input.count()\n",
        "  m = n / t\n",
        "  p = 1 / m / math.log(n*t)\n",
        "  input = input.map(lambda x: (key_fn(x), x))\n",
        "  samples = input.sample(False, p)\n",
        "\n",
        "  sampled_data = samples.collect()\n",
        "\n",
        "  sample_size = len(sampled_data)\n",
        "\n",
        "  sampled_data = sorted(sampled_data)\n",
        "  if len(sampled_data) == 0:\n",
        "    sampled_data = input.take(1)\n",
        "  boundaries = [sampled_data[i * sample_size // t] for i in range(1, t)]\n",
        "\n",
        "  broadcast_boundaries = sc.broadcast(boundaries)\n",
        "\n",
        "  def get_machine(x):\n",
        "    return bisect.bisect_left(broadcast_boundaries.value, x)\n",
        "\n",
        "  inputs_with_machines_ids = input.map(lambda x: (get_machine(x), x))\n",
        "  input_machine_groups = inputs_with_machines_ids.groupByKey()\n",
        "  sorted_within_partitions = input_machine_groups.mapValues(lambda lst: sorted(lst))\n",
        "  if include_ranking:\n",
        "    machine_counts = sorted(sorted_within_partitions.mapValues(len).collect())\n",
        "    machine_counts_broadcast = sc.broadcast(machine_counts)\n",
        "    def count_ranking(machine_id, values):\n",
        "      rank = sum(machine_count for (m_id, machine_count) in machine_counts_broadcast.value if m_id < machine_id)\n",
        "      res = []\n",
        "      for val in values:\n",
        "        (key_fn_val, value) = val\n",
        "        res.append((value, rank))\n",
        "        rank += 1\n",
        "      return res\n",
        "    sorted_inputs = sorted_within_partitions.flatMap(lambda machineId_values: count_ranking(machineId_values[0], machineId_values[1]))\n",
        "  else:\n",
        "    sorted_inputs = sorted_within_partitions.flatMap(lambda machine_keyval: machine_keyval[1])\n",
        "    sorted_inputs = sorted_inputs.map(lambda key_val: key_val[1])\n",
        "  return sorted_inputs\n",
        "\n",
        "terasort(df, lambda x: x[1], True).take(10)"
      ],
      "metadata": {
        "id": "vcJo-Ci7KcJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31644978-7bf2-4c87-b33f-73df8fd733ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((8, 1, False), 0),\n",
              " ((4, 2, False), 1),\n",
              " ((7, 3, True), 2),\n",
              " ((9, 4, True), 3),\n",
              " ((1, 5, False), 4),\n",
              " ((6, 7, False), 5),\n",
              " ((3, 8, True), 6),\n",
              " ((5, 9, True), 7)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log2, ceil\n",
        "n = df.count()\n",
        "DIMS = len(df.take(1)[0]) - 1\n",
        "logn = ceil(log2(n))\n",
        "def int_to_binary_string(num):\n",
        "    return '{0:b}'.format(num).zfill(logn)\n",
        "\n",
        "def label_dimensions(df):\n",
        "  for dim in range(DIMS-1):\n",
        "    df_with_ranking = terasort(df, lambda x: x[dim], True)\n",
        "    df = df_with_ranking.map(lambda val_rank: (*val_rank[0], int_to_binary_string(val_rank[1])))\n",
        "  return df.map(lambda xs_q_ls: (*xs_q_ls[:DIMS+1], (xs_q_ls[DIMS+1:]))) # packing labels into single tuple\n",
        "df_with_labels = label_dimensions(df)\n",
        "df_with_labels.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUGECksEZthi",
        "outputId": "f155b268-698c-4b04-d1a6-aac46fbefaeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 5, False, ('000',)),\n",
              " (3, 8, True, ('001',)),\n",
              " (4, 2, False, ('010',)),\n",
              " (7, 3, True, ('101',)),\n",
              " (8, 1, False, ('110',)),\n",
              " (9, 4, True, ('111',)),\n",
              " (5, 9, True, ('011',)),\n",
              " (6, 7, False, ('100',))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "def get_prefixes(x_y_isquery_label):\n",
        "  (*xs, is_query, labels) = x_y_isquery_label\n",
        "  prefixes = []\n",
        "  for label in labels:\n",
        "    dim_prefixes = []\n",
        "    for idx, c in enumerate(label):\n",
        "      if (c == '1' and is_query) or (c == '0' and not is_query):\n",
        "        dim_prefixes.append(label[:idx])\n",
        "    prefixes.append(dim_prefixes)\n",
        "  prefixes_combs = itertools.product(*prefixes)\n",
        "  return [(*xs, is_query, prefixes) for prefixes in prefixes_combs]\n",
        "\n",
        "df_with_prefixes = df_with_labels.flatMap(get_prefixes)"
      ],
      "metadata": {
        "id": "OZ6uSEjAdoyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_by_prefix = terasort(df_with_prefixes, lambda x_y_isquery_prefix: (x_y_isquery_prefix[-1], x_y_isquery_prefix[-3], x_y_isquery_prefix[-2]), True) # sorting by label, last dim, is_query\n",
        "per_machine = math.ceil(sorted_by_prefix.count() / t)\n",
        "sorted_with_machine_id = sorted_by_prefix.map(lambda value_rank: (value_rank[1] // per_machine, value_rank[0]))\n",
        "sorted_by_prefix_partitions = sorted_with_machine_id.groupByKey()\n",
        "#sorted_by_prefix_partitions.collect()"
      ],
      "metadata": {
        "id": "eVEZyEyckOnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_data_within_partition(machine_id, values):\n",
        "  last_prefix = None\n",
        "  current_data_count = 0\n",
        "  res = []\n",
        "  for (*xs, is_query, prefix) in sorted(values, key=lambda x_y_q_l: (x_y_q_l[-1], x_y_q_l[-3], x_y_q_l[-2])): # sorting by label, last dim, is_query\n",
        "    if last_prefix != prefix:\n",
        "      last_prefix = prefix\n",
        "      current_data_count = 0\n",
        "    if is_query:\n",
        "      res.append((*xs, prefix, current_data_count))\n",
        "    else:\n",
        "      current_data_count += 1\n",
        "  res.append((last_prefix, current_data_count, machine_id))\n",
        "  return res"
      ],
      "metadata": {
        "id": "Zn5_BFTHnNHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts_within_partitions = sorted_by_prefix_partitions.map(lambda k_v: count_data_within_partition(k_v[0], k_v[1]))\n",
        "#counts_within_partitions.collect()"
      ],
      "metadata": {
        "id": "m2UC6o50tlfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_prefixes_counts = counts_within_partitions.map(lambda partition: partition[-1]).collect()\n",
        "prefixes_counts_broadcast = sc.broadcast(last_prefixes_counts)\n",
        "last_prefixes_counts"
      ],
      "metadata": {
        "id": "rUDJQnrpoAra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb84873-7339-4e23-bf98-5967eb229f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('0',), 1, 0), (('11',), 1, 2), (('1',), 1, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_entire_data(lst):\n",
        "  (last_label, last_count, machine_id) = lst[-1]\n",
        "  res = []\n",
        "  for (*xs, prefix, count) in lst[:-1]:\n",
        "    sum_of_previous_counts = sum([count for (label, count, id) in prefixes_counts_broadcast.value if prefix == label and id < machine_id])\n",
        "    res.append(((*xs,), count + sum_of_previous_counts))\n",
        "  return res"
      ],
      "metadata": {
        "id": "xaj-lTlfysMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_counts = counts_within_partitions.flatMap(count_entire_data)\n",
        "all_counts.take(10)"
      ],
      "metadata": {
        "id": "kyY9vZWOzZS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9204db9b-3267-405c-ec0c-dc7c660c53d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((7, 3), 1),\n",
              " ((9, 4), 1),\n",
              " ((5, 9), 1),\n",
              " ((7, 3), 0),\n",
              " ((9, 4), 1),\n",
              " ((3, 8), 1),\n",
              " ((5, 9), 1),\n",
              " ((9, 4), 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_counts = all_counts.groupByKey()\n",
        "summed_counts = aggregated_counts.map(lambda k_v: (k_v[0], sum(k_v[1])))\n",
        "summed_counts.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CesUTjIk6QLN",
        "outputId": "5c377d18-1ad3-4109-d0bf-4725d24eca5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((7, 3), 1), ((5, 9), 2), ((9, 4), 2), ((3, 8), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing generated data\n",
        "def brute(dataset):\n",
        "  res = {}\n",
        "  for el in dataset:\n",
        "    if el[-1]: # is_query\n",
        "      count = 0\n",
        "      for val in dataset:\n",
        "        if val[-1]: # also is query\n",
        "          continue\n",
        "        for dim in range(DIMS):\n",
        "          if el[dim] < val[dim]:\n",
        "            break\n",
        "        else:\n",
        "          count += 1\n",
        "      res[(*el[:-1],)] = count\n",
        "  return res\n",
        "counts = brute(df.collect())\n",
        "are_equal = True\n",
        "for (xs, count) in summed_counts.collect():\n",
        "  #print(x, y, count, counts[(x,y)])\n",
        "  if(count != counts[xs]):\n",
        "    print(\"wrong counts:\", xs, count, '!=', counts[xs])\n",
        "    are_equal = False\n",
        "  counts[xs] = 0\n",
        "for kv in counts:\n",
        "  if counts[kv] != 0:\n",
        "    print(\"wrong counts:\", kv, 0, '!=', counts[kv])\n",
        "    are_equal = False\n",
        "if are_equal:\n",
        "  print(\"Counts are equal\")"
      ],
      "metadata": {
        "id": "SnPq6-hvFxfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd29379-2475-4fb3-b02b-326f8db67b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts are equal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r data.zip 2dims 3dims example_test"
      ],
      "metadata": {
        "id": "2TWroTK1LCvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76c2124-5b60-4bf8-fb2e-f7a68ae3eae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: 2dims/ (stored 0%)\n",
            "  adding: 2dims/part-00000 (deflated 62%)\n",
            "  adding: 2dims/_SUCCESS (stored 0%)\n",
            "  adding: 2dims/.part-00000.crc (stored 0%)\n",
            "  adding: 2dims/._SUCCESS.crc (stored 0%)\n",
            "  adding: 2dims/part-00001 (deflated 62%)\n",
            "  adding: 2dims/.part-00001.crc (stored 0%)\n",
            "  adding: 3dims/ (stored 0%)\n",
            "  adding: 3dims/part-00000 (deflated 59%)\n",
            "  adding: 3dims/_SUCCESS (stored 0%)\n",
            "  adding: 3dims/.part-00000.crc (stored 0%)\n",
            "  adding: 3dims/._SUCCESS.crc (stored 0%)\n",
            "  adding: 3dims/part-00001 (deflated 59%)\n",
            "  adding: 3dims/.part-00001.crc (stored 0%)\n",
            "  adding: example_test/ (stored 0%)\n",
            "  adding: example_test/part-00000 (deflated 30%)\n",
            "  adding: example_test/_SUCCESS (stored 0%)\n",
            "  adding: example_test/.part-00000.crc (stored 0%)\n",
            "  adding: example_test/._SUCCESS.crc (stored 0%)\n",
            "  adding: example_test/part-00001 (deflated 30%)\n",
            "  adding: example_test/.part-00001.crc (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"data.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sTgbjjNmePfe",
        "outputId": "32194b3f-5acb-4111-cab3-5dc28fadd6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ed93302-71b3-4423-91d2-6a6c946a508b\", \"data.zip\", 1156960)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sIfb01Y2eXCN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}